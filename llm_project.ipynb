{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinhyunpark/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jinhyunpark/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import MT5ForConditionalGeneration, AutoTokenizer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from datasets import load_dataset\n",
    "from evaluate import load\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "import evaluate\n",
    "import time\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate the output from the model\n",
    "def generate_output(model, tokenizer, example):\n",
    "    inputs = tokenizer.encode(example, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs, max_new_tokens=np.inf)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jhpark: verified that this is a correct way to use this \n",
    "def calculate_rouge(true_sentence, predicted_sentence):\n",
    "    # jhpark: rouge1/rouge2 (e.g. rouge1, rouge2): n-gram based scoring.\n",
    "    # jhpark: rougeL: Longest common subsequence based scoring.\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = scorer.score(true_sentence, predicted_sentence)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jhpark: verified that this is a correct way to use this \n",
    "def calculate_bleu(true_tokens, predicted_tokens):\n",
    "    '''\n",
    "    * reference for smoothing: A Systematic Comparison of Smoothing Techniques for Sentence-Level BLEU, Boxing Chen and Collin Cherry (2014)\n",
    "    * method1: Smoothing method 1: Add *epsilon* counts to precision with 0 counts.\n",
    "    * https://www.nltk.org/_modules/nltk/translate/bleu_score.html for more details\n",
    "    '''\n",
    "    bleu_score = sentence_bleu(true_tokens, predicted_tokens, smoothing_function=SmoothingFunction().method1)\n",
    "    return bleu_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# english to X is only possible for T5\n",
    "from datasets import load_dataset, load_from_disk\n",
    "\n",
    "# ds_de_en = load_dataset(\"wmt/wmt14\", \"de-en\")\n",
    "# ds_fr_en = load_dataset(\"wmt/wmt15\", \"fr-en\")\n",
    "# ds_ro_en = load_dataset(\"wmt/wmt16\", \"ro-en\")\n",
    "\n",
    "# ds_de_en.save_to_disk(\"../wmt14_de_en\")\n",
    "# ds_fr_en.save_to_disk(\"../wmt15_fr_en\")\n",
    "# ds_ro_en.save_to_disk(\"../wmt16_ro_en\")\n",
    "\n",
    "ds_de_en = load_from_disk(\"../wmt14_de_en\")\n",
    "ds_fr_en = load_from_disk(\"../wmt15_fr_en\")\n",
    "ds_ro_en = load_from_disk(\"../wmt16_ro_en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with small\n",
      "Done with base\n"
     ]
    }
   ],
   "source": [
    "t5_tokenizer_small = AutoTokenizer.from_pretrained('t5-small')\n",
    "t5_model_small = AutoModelForSeq2SeqLM.from_pretrained('t5-small')\n",
    "print(\"Done with small\")\n",
    "\n",
    "t5_tokenizer_base = AutoTokenizer.from_pretrained('t5-base')\n",
    "t5_model_base = AutoModelForSeq2SeqLM.from_pretrained('t5-base')\n",
    "print(\"Done with base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generate translations (German to English)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German to English\n",
      "------------ Sample 1 ------------\n",
      "[Sentences]\n",
      " Input: translate English to German: Resumption of the session\n",
      " True Translation: Wiederaufnahme der Sitzungsperiode\n",
      " Predicted Translation: Wiederaufnahme der Sitzungsperiode\n",
      "\n",
      "[Scores]\n",
      " BLEU score: 1.0\n",
      " METEOR score: 0.9993141289437586\n",
      " ROUGE scores: {'rouge1': Score(precision=1.0, recall=1.0, fmeasure=1.0), 'rouge2': Score(precision=1.0, recall=1.0, fmeasure=1.0), 'rougeL': Score(precision=1.0, recall=1.0, fmeasure=1.0)}\n",
      " \n",
      "German to English\n",
      "------------ Sample 2 ------------\n",
      "[Sentences]\n",
      " Input: translate English to German: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.\n",
      " True Translation: Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.\n",
      " Predicted Translation: Ich erkläre die am Freitag, dem 17. Dezember 1999 unterbrochene Sitzungsperiode des Europäischen Parlaments für wieder aufgenommen, und ich möchte Ihnen erneut ein glückliches neues Jahr wünschen, in der Hoffnung, dass Sie einen angenehmen Festtag genießen.\n",
      "\n",
      "[Scores]\n",
      " BLEU score: 0.4955474787092686\n",
      " METEOR score: 0.6400087260034905\n",
      " ROUGE scores: {'rouge1': Score(precision=0.4883720930232558, recall=0.6176470588235294, fmeasure=0.5454545454545455), 'rouge2': Score(precision=0.35714285714285715, recall=0.45454545454545453, fmeasure=0.4), 'rougeL': Score(precision=0.4418604651162791, recall=0.5588235294117647, fmeasure=0.49350649350649345)}\n",
      " \n",
      "German to English\n",
      "------------ Sample 3 ------------\n",
      "[Sentences]\n",
      " Input: translate English to German: Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\n",
      " True Translation: Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.\n",
      " Predicted Translation: Obwohl, wie Sie gesehen haben, der gefürchtete \"Millennium-Fehler\" nicht zustande kam, erlitten die Menschen in einigen Ländern noch immer eine Reihe von Naturkatastrophen, die wirklich schrecklich waren.\n",
      "\n",
      "[Scores]\n",
      " BLEU score: 0.258758268765002\n",
      " METEOR score: 0.5387931034482759\n",
      " ROUGE scores: {'rouge1': Score(precision=0.26666666666666666, recall=0.3333333333333333, fmeasure=0.2962962962962963), 'rouge2': Score(precision=0.10344827586206896, recall=0.13043478260869565, fmeasure=0.11538461538461538), 'rougeL': Score(precision=0.26666666666666666, recall=0.3333333333333333, fmeasure=0.2962962962962963)}\n",
      " \n",
      "German to English\n",
      "------------ Sample 4 ------------\n",
      "[Sentences]\n",
      " Input: translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.\n",
      " True Translation: Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.\n",
      " Predicted Translation: Sie haben in den nächsten Tagen, während dieser Sitzung, eine Aussprache zu diesem Thema beantragt.\n",
      "\n",
      "[Scores]\n",
      " BLEU score: 0.251696695878184\n",
      " METEOR score: 0.41573183760683763\n",
      " ROUGE scores: {'rouge1': Score(precision=0.4117647058823529, recall=0.4117647058823529, fmeasure=0.4117647058823529), 'rouge2': Score(precision=0.25, recall=0.25, fmeasure=0.25), 'rougeL': Score(precision=0.29411764705882354, recall=0.29411764705882354, fmeasure=0.29411764705882354)}\n",
      " \n",
      "German to English\n",
      "------------ Sample 5 ------------\n",
      "[Sentences]\n",
      " Input: translate English to German: In the meantime, I should like to observe a minute' s silence, as a number of Members have requested, on behalf of all the victims concerned, particularly those of the terrible storms, in the various countries of the European Union.\n",
      " True Translation: Heute möchte ich Sie bitten - das ist auch der Wunsch einiger Kolleginnen und Kollegen -, allen Opfern der Stürme, insbesondere in den verschiedenen Ländern der Europäischen Union, in einer Schweigeminute zu gedenken.\n",
      " Predicted Translation: In der Zwischenzeit möchte ich, wie einige Abgeordnete es gefordert haben, im Namen aller betroffenen Opfer, insbesondere der schrecklichen Stürme, in den verschiedenen Ländern der Europäischen Union eine Schweigeminute einlegen.\n",
      "\n",
      "[Scores]\n",
      " BLEU score: 0.2910242261957368\n",
      " METEOR score: 0.5503142295750778\n",
      " ROUGE scores: {'rouge1': Score(precision=0.5882352941176471, recall=0.5714285714285714, fmeasure=0.5797101449275363), 'rouge2': Score(precision=0.3333333333333333, recall=0.3235294117647059, fmeasure=0.3283582089552239), 'rougeL': Score(precision=0.5, recall=0.4857142857142857, fmeasure=0.49275362318840576)}\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"German to English\")\n",
    "    print(f\"------------ Sample {i+1} ------------\")\n",
    "    \n",
    "    input_text = f\"translate English to German: {ds_de_en['train'][i]['translation']['en']}\"\n",
    "    true_translation = ds_de_en['train'][i]['translation']['de']\n",
    "    predicted_translation = generate_output(model=t5_model_small, tokenizer=t5_tokenizer_small, example=input_text)\n",
    "    assert type(input_text) == type(true_translation)   # str\n",
    "    assert type(true_translation) == type(predicted_translation)\n",
    "\n",
    "    true_tokens = t5_tokenizer_small.tokenize(true_translation)\n",
    "    predicted_tokens = t5_tokenizer_small.tokenize(predicted_translation)\n",
    "    assert type(true_tokens) == type(predicted_tokens)  # list\n",
    "\n",
    "    print(\"[Sentences]\")\n",
    "    print(\" Input:\", input_text)\n",
    "    print(\" True Translation:\", true_translation)\n",
    "    print(\" Predicted Translation:\", predicted_translation)\n",
    "    \n",
    "    print(\"\\n[Scores]\")\n",
    "    # 1. BLEU\n",
    "    bleu = calculate_bleu([true_tokens], predicted_tokens)\n",
    "    print(\" BLEU score:\", bleu)\n",
    "    # 2. METEOR (# jhpark: verified that this is a correct way to use this.)\n",
    "    meteor = meteor_score([true_tokens], predicted_tokens)\n",
    "    print(\" METEOR score:\", meteor)\n",
    "    # 3. ROUGE\n",
    "    rouge = calculate_rouge(true_translation, predicted_translation)\n",
    "    print(\" ROUGE scores:\", rouge)\n",
    "\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate translations (French to English)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French to English\n",
      "------------ Sample 1 ------------\n",
      "[Sentences]\n",
      " Input: translate English to French: Resumption of the session\n",
      " True Translation: Reprise de la session\n",
      " Predicted Translation: Reprise de la session\n",
      "\n",
      "[Scores]\n",
      " BLEU score: 1.0\n",
      " METEOR score: 0.996\n",
      " ROUGE scores: {'rouge1': Score(precision=1.0, recall=1.0, fmeasure=1.0), 'rouge2': Score(precision=1.0, recall=1.0, fmeasure=1.0), 'rougeL': Score(precision=1.0, recall=1.0, fmeasure=1.0)}\n",
      " \n",
      "French to English\n",
      "------------ Sample 2 ------------\n",
      "[Sentences]\n",
      " Input: translate English to French: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.\n",
      " True Translation: Je déclare reprise la session du Parlement européen qui avait été interrompue le vendredi 17 décembre dernier et je vous renouvelle tous mes vux en espérant que vous avez passé de bonnes vacances.\n",
      " Predicted Translation: Je déclare reprise la session du Parlement européen interrompue le vendredi 17 décembre 1999 et je voudrais vous souhaiter une nouvelle année heureuse dans l'espoir que vous avez eu une agréable période festive.\n",
      "\n",
      "[Scores]\n",
      " BLEU score: 0.40696592157185546\n",
      " METEOR score: 0.575153374233129\n",
      " ROUGE scores: {'rouge1': Score(precision=0.55, recall=0.5945945945945946, fmeasure=0.5714285714285715), 'rouge2': Score(precision=0.4358974358974359, recall=0.4722222222222222, fmeasure=0.45333333333333337), 'rougeL': Score(precision=0.55, recall=0.5945945945945946, fmeasure=0.5714285714285715)}\n",
      " \n",
      "French to English\n",
      "------------ Sample 3 ------------\n",
      "[Sentences]\n",
      " Input: translate English to French: Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\n",
      " True Translation: Comme vous avez pu le constater, le grand \"bogue de l'an 2000\" ne s'est pas produit. En revanche, les citoyens d'un certain nombre de nos pays ont été victimes de catastrophes naturelles qui ont vraiment été terribles.\n",
      " Predicted Translation: Bien que, comme vous l'avez vu, le bogue du millénaire n'ait pas eu lieu, les populations d'un certain nombre de pays ont encore subi une série de catastrophes naturelles qui étaient vraiment épouvantables.\n",
      "\n",
      "[Scores]\n",
      " BLEU score: 0.24633861210301242\n",
      " METEOR score: 0.5377632542268387\n",
      " ROUGE scores: {'rouge1': Score(precision=0.5526315789473685, recall=0.525, fmeasure=0.5384615384615385), 'rouge2': Score(precision=0.24324324324324326, recall=0.23076923076923078, fmeasure=0.23684210526315788), 'rougeL': Score(precision=0.5, recall=0.475, fmeasure=0.48717948717948717)}\n",
      " \n",
      "French to English\n",
      "------------ Sample 4 ------------\n",
      "[Sentences]\n",
      " Input: translate English to French: You have requested a debate on this subject in the course of the next few days, during this part-session.\n",
      " True Translation: Vous avez souhaité un débat à ce sujet dans les prochains jours, au cours de cette période de session.\n",
      " Predicted Translation: Vous avez demandé un débat sur ce sujet au cours des prochains jours, durant cette période de session.\n",
      "\n",
      "[Scores]\n",
      " BLEU score: 0.4095272735780044\n",
      " METEOR score: 0.8076739237695818\n",
      " ROUGE scores: {'rouge1': Score(precision=0.8, recall=0.8, fmeasure=0.8000000000000002), 'rouge2': Score(precision=0.5263157894736842, recall=0.5263157894736842, fmeasure=0.5263157894736842), 'rougeL': Score(precision=0.7, recall=0.7, fmeasure=0.7)}\n",
      " \n",
      "French to English\n",
      "------------ Sample 5 ------------\n",
      "[Sentences]\n",
      " Input: translate English to French: In the meantime, I should like to observe a minute' s silence, as a number of Members have requested, on behalf of all the victims concerned, particularly those of the terrible storms, in the various countries of the European Union.\n",
      " True Translation: En attendant, je souhaiterais, comme un certain nombre de collègues me l'ont demandé, que nous observions une minute de silence pour toutes les victimes, des tempêtes notamment, dans les différents pays de l'Union européenne qui ont été touchés.\n",
      " Predicted Translation: Entre-temps, je voudrais observer une minute de silence, comme l'ont demandé plusieurs députés, au nom de toutes les victimes concernées, en particulier celles des terribles tempêtes, dans les différents pays de l'Union européenne.\n",
      "\n",
      "[Scores]\n",
      " BLEU score: 0.37246522718389913\n",
      " METEOR score: 0.6119151261612678\n",
      " ROUGE scores: {'rouge1': Score(precision=0.6666666666666666, recall=0.6222222222222222, fmeasure=0.6436781609195403), 'rouge2': Score(precision=0.4146341463414634, recall=0.38636363636363635, fmeasure=0.39999999999999997), 'rougeL': Score(precision=0.5238095238095238, recall=0.4888888888888889, fmeasure=0.5057471264367817)}\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"French to English\")\n",
    "    print(f\"------------ Sample {i+1} ------------\")\n",
    "    \n",
    "    input_text = f\"translate English to French: {ds_fr_en['train'][i]['translation']['en']}\"\n",
    "    true_translation = ds_fr_en['train'][i]['translation']['fr']\n",
    "    predicted_translation = generate_output(model=t5_model_small, tokenizer=t5_tokenizer_small, example=input_text)\n",
    "    assert type(input_text) == type(true_translation)   # str\n",
    "    assert type(true_translation) == type(predicted_translation)\n",
    "\n",
    "    true_tokens = t5_tokenizer_small.tokenize(true_translation)\n",
    "    predicted_tokens = t5_tokenizer_small.tokenize(predicted_translation)\n",
    "    assert type(true_tokens) == type(predicted_tokens)  # list\n",
    "\n",
    "    print(\"[Sentences]\")\n",
    "    print(\" Input:\", input_text)\n",
    "    print(\" True Translation:\", true_translation)\n",
    "    print(\" Predicted Translation:\", predicted_translation)\n",
    "    \n",
    "    print(\"\\n[Scores]\")\n",
    "    # 1. BLEU\n",
    "    bleu = calculate_bleu([true_tokens], predicted_tokens)\n",
    "    print(\" BLEU score:\", bleu)\n",
    "    # 2. METEOR (# jhpark: verified that this is a correct way to use this.)\n",
    "    meteor = meteor_score([true_tokens], predicted_tokens)\n",
    "    print(\" METEOR score:\", meteor)\n",
    "    # 3. ROUGE\n",
    "    rouge = calculate_rouge(true_translation, predicted_translation)\n",
    "    print(\" ROUGE scores:\", rouge)\n",
    "\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Generate translations (Romanian to English)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Romanian to English\n",
      "------------ Sample 1 ------------\n",
      "[Sentences]\n",
      " Input: translate English to Romanian: Membership of Parliament: see Minutes\n",
      " True Translation: Componenţa Parlamentului: a se vedea procesul-verbal\n",
      " Predicted Translation: Componenţa Parlamentului: a se vedea procesul-verbal\n",
      "\n",
      "[Scores]\n",
      " BLEU score: 1.0\n",
      " METEOR score: 0.9998177842565598\n",
      " ROUGE scores: {'rouge1': Score(precision=1.0, recall=1.0, fmeasure=1.0), 'rouge2': Score(precision=1.0, recall=1.0, fmeasure=1.0), 'rougeL': Score(precision=1.0, recall=1.0, fmeasure=1.0)}\n",
      " \n",
      "Romanian to English\n",
      "------------ Sample 2 ------------\n",
      "[Sentences]\n",
      " Input: translate English to Romanian: Approval of Minutes of previous sitting: see Minutes\n",
      " True Translation: Aprobarea procesului-verbal al şedinţei precedente: a se vedea procesul-verbal\n",
      " Predicted Translation: Aprobarea procesului-verbal al şedinţei precedente: a se vedea procesul-verbal\n",
      "\n",
      "[Scores]\n",
      " BLEU score: 1.0\n",
      " METEOR score: 0.999958905235473\n",
      " ROUGE scores: {'rouge1': Score(precision=1.0, recall=1.0, fmeasure=1.0), 'rouge2': Score(precision=1.0, recall=1.0, fmeasure=1.0), 'rougeL': Score(precision=1.0, recall=1.0, fmeasure=1.0)}\n",
      " \n",
      "Romanian to English\n",
      "------------ Sample 3 ------------\n",
      "[Sentences]\n",
      " Input: translate English to Romanian: Membership of Parliament: see Minutes\n",
      " True Translation: Componenţa Parlamentului: a se vedea procesul-verbal\n",
      " Predicted Translation: Componenţa Parlamentului: a se vedea procesul-verbal\n",
      "\n",
      "[Scores]\n",
      " BLEU score: 1.0\n",
      " METEOR score: 0.9998177842565598\n",
      " ROUGE scores: {'rouge1': Score(precision=1.0, recall=1.0, fmeasure=1.0), 'rouge2': Score(precision=1.0, recall=1.0, fmeasure=1.0), 'rougeL': Score(precision=1.0, recall=1.0, fmeasure=1.0)}\n",
      " \n",
      "Romanian to English\n",
      "------------ Sample 4 ------------\n",
      "[Sentences]\n",
      " Input: translate English to Romanian: Verification of credentials: see Minutes\n",
      " True Translation: Verificarea prerogativelor: a se vedea procesul-verbal\n",
      " Predicted Translation: Verificarea prerogativelor: a se vedea procesul-verbal\n",
      "\n",
      "[Scores]\n",
      " BLEU score: 1.0\n",
      " METEOR score: 0.9998779296875\n",
      " ROUGE scores: {'rouge1': Score(precision=1.0, recall=1.0, fmeasure=1.0), 'rouge2': Score(precision=1.0, recall=1.0, fmeasure=1.0), 'rougeL': Score(precision=1.0, recall=1.0, fmeasure=1.0)}\n",
      " \n",
      "Romanian to English\n",
      "------------ Sample 5 ------------\n",
      "[Sentences]\n",
      " Input: translate English to Romanian: Documents received: see Minutes\n",
      " True Translation: Depunere de documente: a se vedea procesul-verbal\n",
      " Predicted Translation: Depunerea documentelor: a se vedea procesul-verbal\n",
      "\n",
      "[Scores]\n",
      " BLEU score: 0.540856266901231\n",
      " METEOR score: 0.6935305574564405\n",
      " ROUGE scores: {'rouge1': Score(precision=0.7142857142857143, recall=0.625, fmeasure=0.6666666666666666), 'rouge2': Score(precision=0.6666666666666666, recall=0.5714285714285714, fmeasure=0.6153846153846153), 'rougeL': Score(precision=0.7142857142857143, recall=0.625, fmeasure=0.6666666666666666)}\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(\"Romanian to English\")\n",
    "    print(f\"------------ Sample {i+1} ------------\")\n",
    "    \n",
    "    input_text = f\"translate English to Romanian: {ds_ro_en['train'][i]['translation']['en']}\"\n",
    "    true_translation = ds_ro_en['train'][i]['translation']['ro']\n",
    "    predicted_translation = generate_output(model=t5_model_small, tokenizer=t5_tokenizer_small, example=input_text)\n",
    "    assert type(input_text) == type(true_translation)   # str\n",
    "    assert type(true_translation) == type(predicted_translation)\n",
    "\n",
    "    true_tokens = t5_tokenizer_small.tokenize(true_translation)\n",
    "    predicted_tokens = t5_tokenizer_small.tokenize(predicted_translation)\n",
    "    assert type(true_tokens) == type(predicted_tokens)  # list\n",
    "\n",
    "    print(\"[Sentences]\")\n",
    "    print(\" Input:\", input_text)\n",
    "    print(\" True Translation:\", true_translation)\n",
    "    print(\" Predicted Translation:\", predicted_translation)\n",
    "    \n",
    "    print(\"\\n[Scores]\")\n",
    "    # 1. BLEU\n",
    "    bleu = calculate_bleu([true_tokens], predicted_tokens)\n",
    "    print(\" BLEU score:\", bleu)\n",
    "    # 2. METEOR (# jhpark: verified that this is a correct way to use this.)\n",
    "    meteor = meteor_score([true_tokens], predicted_tokens)\n",
    "    print(\" METEOR score:\", meteor)\n",
    "    # 3. ROUGE\n",
    "    rouge = calculate_rouge(true_translation, predicted_translation)\n",
    "    print(\" ROUGE scores:\", rouge)\n",
    "\n",
    "    print(\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

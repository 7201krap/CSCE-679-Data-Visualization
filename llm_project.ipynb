{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinhyunpark/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jinhyunpark/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import MT5ForConditionalGeneration, AutoTokenizer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from datasets import load_dataset\n",
    "from evaluate import load\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "import evaluate\n",
    "import time\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('wordnet')\n",
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate the output from the model\n",
    "def generate_output(model, tokenizer, example):\n",
    "    inputs = tokenizer.encode(example, return_tensors=\"pt\")\n",
    "    outputs = model.generate(inputs, max_new_tokens=np.inf)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rouge(true_sentence, predicted_sentence):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    scores = scorer.score(true_sentence, predicted_sentence)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu(true_sentence, predicted_sentence):\n",
    "    true_tokens = true_sentence.split()\n",
    "    predicted_tokens = predicted_sentence.split()\n",
    "    smoothie = SmoothingFunction().method1\n",
    "    bleu_score = sentence_bleu([true_tokens], predicted_tokens, smoothing_function=smoothie)\n",
    "    return bleu_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# english to X is only possible for T5\n",
    "from datasets import load_dataset, load_from_disk\n",
    "\n",
    "# ds_de_en = load_dataset(\"wmt/wmt14\", \"de-en\")\n",
    "# ds_fr_en = load_dataset(\"wmt/wmt15\", \"fr-en\")\n",
    "# ds_ro_en = load_dataset(\"wmt/wmt16\", \"ro-en\")\n",
    "\n",
    "# ds_de_en.save_to_disk(\"../wmt14_de_en\")\n",
    "# ds_fr_en.save_to_disk(\"../wmt15_fr_en\")\n",
    "# ds_ro_en.save_to_disk(\"../wmt16_ro_en\")\n",
    "\n",
    "ds_de_en = load_from_disk(\"../wmt14_de_en\")\n",
    "ds_fr_en = load_from_disk(\"../wmt15_fr_en\")\n",
    "ds_ro_en = load_from_disk(\"../wmt16_ro_en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with small\n",
      "Done with base\n"
     ]
    }
   ],
   "source": [
    "t5_tokenizer_small = AutoTokenizer.from_pretrained('t5-small')\n",
    "t5_model_small = AutoModelForSeq2SeqLM.from_pretrained('t5-small')\n",
    "print(\"Done with small\")\n",
    "\n",
    "t5_tokenizer_base = AutoTokenizer.from_pretrained('t5-base')\n",
    "t5_model_base = AutoModelForSeq2SeqLM.from_pretrained('t5-base')\n",
    "print(\"Done with base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Sample 1 ------------\n",
      "Input: translate English to German: Resumption of the session\n",
      "True Translation: Wiederaufnahme der Sitzungsperiode\n",
      "Predicted Translation: Wiederaufnahme der Sitzungsperiode\n",
      "METEOR score: 0.9993141289437586\n",
      "ROUGE scores: {'rouge1': Score(precision=1.0, recall=1.0, fmeasure=1.0), 'rouge2': Score(precision=1.0, recall=1.0, fmeasure=1.0), 'rougeL': Score(precision=1.0, recall=1.0, fmeasure=1.0)}\n",
      "BLEU score: 0.5623413251903491\n",
      " \n",
      "------------ Sample 2 ------------\n",
      "Input: translate English to German: I declare resumed the session of the European Parliament adjourned on Friday 17 December 1999, and I would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period.\n",
      "True Translation: Ich erkläre die am Freitag, dem 17. Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen, wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe, daß Sie schöne Ferien hatten.\n",
      "Predicted Translation: Ich erkläre die am Freitag, dem 17. Dezember 1999 unterbrochene Sitzungsperiode des Europäischen Parlaments für wieder aufgenommen, und ich möchte Ihnen erneut ein glückliches neues Jahr wünschen, in der Hoffnung, dass Sie einen angenehmen Festtag genießen.\n",
      "METEOR score: 0.6400087260034905\n",
      "ROUGE scores: {'rouge1': Score(precision=0.4883720930232558, recall=0.6176470588235294, fmeasure=0.5454545454545455), 'rouge2': Score(precision=0.35714285714285715, recall=0.45454545454545453, fmeasure=0.4), 'rougeL': Score(precision=0.4418604651162791, recall=0.5588235294117647, fmeasure=0.49350649350649345)}\n",
      "BLEU score: 0.32778508488039954\n",
      " \n",
      "------------ Sample 3 ------------\n",
      "Input: translate English to German: Although, as you will have seen, the dreaded 'millennium bug' failed to materialise, still the people in a number of countries suffered a series of natural disasters that truly were dreadful.\n",
      "True Translation: Wie Sie feststellen konnten, ist der gefürchtete \"Millenium-Bug \" nicht eingetreten. Doch sind Bürger einiger unserer Mitgliedstaaten Opfer von schrecklichen Naturkatastrophen geworden.\n",
      "Predicted Translation: Obwohl, wie Sie gesehen haben, der gefürchtete \"Millennium-Fehler\" nicht zustande kam, erlitten die Menschen in einigen Ländern noch immer eine Reihe von Naturkatastrophen, die wirklich schrecklich waren.\n",
      "METEOR score: 0.5387931034482759\n",
      "ROUGE scores: {'rouge1': Score(precision=0.26666666666666666, recall=0.3333333333333333, fmeasure=0.2962962962962963), 'rouge2': Score(precision=0.10344827586206896, recall=0.13043478260869565, fmeasure=0.11538461538461538), 'rougeL': Score(precision=0.26666666666666666, recall=0.3333333333333333, fmeasure=0.2962962962962963)}\n",
      "BLEU score: 0.018561813742586367\n",
      " \n",
      "------------ Sample 4 ------------\n",
      "Input: translate English to German: You have requested a debate on this subject in the course of the next few days, during this part-session.\n",
      "True Translation: Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.\n",
      "Predicted Translation: Sie haben in den nächsten Tagen, während dieser Sitzung, eine Aussprache zu diesem Thema beantragt.\n",
      "METEOR score: 0.41573183760683763\n",
      "ROUGE scores: {'rouge1': Score(precision=0.4117647058823529, recall=0.4117647058823529, fmeasure=0.4117647058823529), 'rouge2': Score(precision=0.25, recall=0.25, fmeasure=0.25), 'rougeL': Score(precision=0.29411764705882354, recall=0.29411764705882354, fmeasure=0.29411764705882354)}\n",
      "BLEU score: 0.0695362172133984\n",
      " \n",
      "------------ Sample 5 ------------\n",
      "Input: translate English to German: In the meantime, I should like to observe a minute' s silence, as a number of Members have requested, on behalf of all the victims concerned, particularly those of the terrible storms, in the various countries of the European Union.\n",
      "True Translation: Heute möchte ich Sie bitten - das ist auch der Wunsch einiger Kolleginnen und Kollegen -, allen Opfern der Stürme, insbesondere in den verschiedenen Ländern der Europäischen Union, in einer Schweigeminute zu gedenken.\n",
      "Predicted Translation: In der Zwischenzeit möchte ich, wie einige Abgeordnete es gefordert haben, im Namen aller betroffenen Opfer, insbesondere der schrecklichen Stürme, in den verschiedenen Ländern der Europäischen Union eine Schweigeminute einlegen.\n",
      "METEOR score: 0.5503142295750778\n",
      "ROUGE scores: {'rouge1': Score(precision=0.5882352941176471, recall=0.5714285714285714, fmeasure=0.5797101449275363), 'rouge2': Score(precision=0.3333333333333333, recall=0.3235294117647059, fmeasure=0.3283582089552239), 'rougeL': Score(precision=0.5, recall=0.4857142857142857, fmeasure=0.49275362318840576)}\n",
      "BLEU score: 0.16458619833941865\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(f\"------------ Sample {i+1} ------------\")\n",
    "    \n",
    "    input_text = f\"translate English to German: {ds_de_en['train'][i]['translation']['en']}\"\n",
    "    true_translation = ds_de_en['train'][i]['translation']['de']\n",
    "    predicted_translation = generate_output(model=t5_model_small, tokenizer=t5_tokenizer_small, example=input_text)\n",
    "\n",
    "    true_tokens = t5_tokenizer_small.tokenize(true_translation)\n",
    "    predicted_tokens = t5_tokenizer_small.tokenize(predicted_translation)\n",
    "\n",
    "    print(\"Input:\", input_text)\n",
    "    print(\"True Translation:\", true_translation)\n",
    "    print(\"Predicted Translation:\", predicted_translation)\n",
    "    \n",
    "    # 1. METEOR\n",
    "    print(\"METEOR score:\", meteor_score([true_tokens], predicted_tokens))\n",
    "    # 2. ROUGE\n",
    "    rouge_scores = calculate_rouge(true_translation, predicted_translation)\n",
    "    print(\"ROUGE scores:\", rouge_scores)\n",
    "    # 3. BLEU\n",
    "    bleu_score = calculate_bleu(true_translation, predicted_translation)\n",
    "    print(\"BLEU score:\", bleu_score)\n",
    "\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
